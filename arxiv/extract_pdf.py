import os
import re
import fitz  # PyMuPDF
import requests
import tempfile

def format_text_with_positions(text_with_positions):
    """
    åŸºæ–¼ä½ç½®è®ŠåŒ–çš„æ™ºèƒ½åˆ†æ®µè™•ç†ï¼š
    - æª¢æ¸¬è¡Œé¦–ä½ç½®çš„æ˜é¡¯è®ŠåŒ–ä¾†åˆ¤æ–·æ®µè½é–‹å§‹
    - ç²—é«”æ–‡å­—è‡ªå‹•æˆç‚ºç« ç¯€æ¨™é¡Œ
    - å…¬å¼å’Œç‰¹æ®Šæ ¼å¼ä¿æŒç¨ç«‹
    """
    if not text_with_positions:
        return ""
    
    paragraphs = []
    current_paragraph = []
    
    # åˆ†ææ‰€æœ‰è¡Œçš„ x ä½ç½®ï¼Œæ‰¾å‡ºå¸¸è¦‹çš„å·¦é‚Šè·æ¨¡å¼
    x_positions = [item['x_position'] for item in text_with_positions if item['x_position'] is not None]
    
    # è¨ˆç®—ä½ç½®çš„çµ±è¨ˆè³‡è¨Š
    if x_positions:
        min_x = min(x_positions)
        max_x = max(x_positions)
        
        # å°‡ä½ç½®åˆ†çµ„ï¼Œå®¹å¿åº¦ç‚º 5 åƒç´ 
        position_groups = {}
        for x in x_positions:
            rounded_x = round(x / 5) * 5  # å°‡ä½ç½®å››æ¨äº”å…¥åˆ°æœ€è¿‘çš„ 5 åƒç´ 
            position_groups[rounded_x] = position_groups.get(rounded_x, 0) + 1
        
        # æ‰¾å‡ºæœ€å¸¸è¦‹çš„å·¦é‚Šè·ï¼ˆæ­£æ–‡ä½ç½®ï¼‰
        main_x_position = max(position_groups.keys(), key=position_groups.get)
        
        # è¨­å®šä½ç½®è®ŠåŒ–çš„é–¾å€¼
        position_threshold = 10  # åƒç´ 
    else:
        main_x_position = 0
        position_threshold = 10
    
    for i, item in enumerate(text_with_positions):
        text = item['text']
        x_pos = item['x_position']
        is_bold = item['is_bold']
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºç²—é«”æ¨™é¡Œ
        is_bold_title = bool(re.match(r'^\*\*.*\*\*$', text))
        
        # å¦‚æœæ˜¯ç²—é«”æ¨™é¡Œï¼Œç›´æ¥ä½œç‚ºç¨ç«‹æ®µè½
        if is_bold_title:
            # å®Œæˆç•¶å‰æ®µè½
            if current_paragraph:
                paragraph_text = ' '.join(current_paragraph).strip()
                if paragraph_text:
                    paragraphs.append(paragraph_text)
                current_paragraph = []
            
            # ç²—é«”æ¨™é¡Œè½‰æ›ç‚º Markdown æ¨™é¡Œ
            title_text = text.replace('**', '').strip()
            paragraphs.append(f"## {title_text}")
            continue
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ–°æ®µè½é–‹å§‹
        is_paragraph_start = False
        
        # æ¢ä»¶1ï¼šä½ç½®è®ŠåŒ–æª¢æ¸¬ - é€™æ˜¯æ ¸å¿ƒé‚è¼¯
        if i > 0 and x_pos is not None:
            prev_item = text_with_positions[i-1]
            prev_x_pos = prev_item['x_position']
            
            if prev_x_pos is not None:
                # æª¢æ¸¬ä½ç½®çš„æ˜é¡¯è®ŠåŒ–
                x_diff = abs(x_pos - prev_x_pos)
                
                # å¦‚æœä½ç½®è®ŠåŒ–è¶…éé–¾å€¼ï¼Œä¸”ç•¶å‰è¡Œé¦–å­—æ¯å¤§å¯«ï¼Œå¯èƒ½æ˜¯æ–°æ®µè½
                if x_diff > position_threshold and text and text[0].isupper():
                    is_paragraph_start = True
                
                # å¦‚æœå¾ç¸®æ’ä½ç½®å›åˆ°ä¸»ä½ç½®ï¼Œä¹Ÿæ˜¯æ–°æ®µè½
                if (abs(prev_x_pos - main_x_position) > position_threshold and 
                    abs(x_pos - main_x_position) <= position_threshold and 
                    text and text[0].isupper()):
                    is_paragraph_start = True
                
                # å¦‚æœå¾ä¸»ä½ç½®ç§»å‹•åˆ°æ˜é¡¯çš„ç¸®æ’ä½ç½®ï¼Œä¹Ÿæ˜¯æ–°æ®µè½
                if (abs(prev_x_pos - main_x_position) <= position_threshold and 
                    abs(x_pos - main_x_position) > position_threshold and 
                    text and text[0].isupper()):
                    is_paragraph_start = True
        
        # æ¢ä»¶2ï¼šå­¸è¡“ç« ç¯€æ¨™é¡Œï¼ˆå…¨å¤§å¯«çŸ­è©ï¼‰
        academic_sections = [
            'ABSTRACT', 'INTRODUCTION', 'METHODOLOGY', 'METHODS', 'RESULTS',
            'DISCUSSION', 'CONCLUSION', 'CONCLUSIONS', 'ACKNOWLEDGEMENTS',
            'ACKNOWLEDGMENTS', 'REFERENCES', 'BIBLIOGRAPHY', 'APPENDIX',
            'KEYWORDS', 'KEY WORDS'
        ]
        
        if text.upper() in academic_sections:
            is_paragraph_start = True
        
        # æ¢ä»¶3ï¼šç·¨è™Ÿåˆ—è¡¨
        if re.match(r'^\d+\.\s+', text) or re.match(r'^[a-z]\.\s+', text):
            is_paragraph_start = True
        
        # æ¢ä»¶4ï¼šåœ–è¡¨å¼•ç”¨
        if re.match(r'^(Fig\.|Figure|Table|Equation)\s+\d+', text, re.IGNORECASE):
            is_paragraph_start = True
        
        # æ¢ä»¶5ï¼šæ˜é¡¯çš„æ®µè½é–‹å§‹æ¨™èªŒè©
        paragraph_indicators = [
            'However,', 'Therefore,', 'Moreover,', 'Furthermore,', 'Nevertheless,',
            'Additionally,', 'Similarly,', 'Consequently,', 'Meanwhile,', 'Thus,',
            'In particular,', 'For example,', 'In contrast,', 'On the other hand,'
        ]
        
        for indicator in paragraph_indicators:
            if text.startswith(indicator):
                is_paragraph_start = True
                break
        
        # å¦‚æœæª¢æ¸¬åˆ°æ–°æ®µè½é–‹å§‹ä¸”ç•¶å‰æ®µè½ä¸ç‚ºç©º
        if is_paragraph_start and current_paragraph:
            paragraph_text = ' '.join(current_paragraph).strip()
            if paragraph_text:
                paragraphs.append(paragraph_text)
            current_paragraph = []
        
        # æ·»åŠ åˆ°ç•¶å‰æ®µè½
        current_paragraph.append(text)
    
    # è™•ç†æœ€å¾Œä¸€å€‹æ®µè½
    if current_paragraph:
        paragraph_text = ' '.join(current_paragraph).strip()
        if paragraph_text:
            paragraphs.append(paragraph_text)
    
    # åˆä½µæˆæœ€çµ‚æ–‡å­—ï¼Œæ®µè½é–“ç”¨é›™æ›è¡Œåˆ†éš”
    return '\n\n'.join(paragraphs)

def download_arxiv_pdf(arxiv_id, output_path):
    """ä¸‹è¼‰ arXiv è«–æ–‡ PDF"""
    import urllib.request
    
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    url = f"https://arxiv.org/pdf/{arxiv_id}.pdf"
    
    print(f"ğŸ“¥ æ­£åœ¨ä¸‹è¼‰: {url}")
    urllib.request.urlretrieve(url, output_path)
    print(f"âœ… ä¸‹è¼‰å®Œæˆ: {output_path}")

def extract_from_pdf(pdf_path, output_dir):
    """
    å¾ PDF æª”æ¡ˆä¸­æå–æ‰€æœ‰æ–‡å­—ã€å…¬å¼ã€åœ–ç‰‡ï¼Œå„²å­˜ç‚º Markdown èˆ‡ PNG æ ¼å¼ã€‚
    æ”¯æ´æœ¬åœ°æª”æ¡ˆè·¯å¾‘å’Œ URLã€‚
    """
    os.makedirs(output_dir, exist_ok=True)
    img_dir = os.path.join(output_dir, "images")
    os.makedirs(img_dir, exist_ok=True)

    text_md_path = os.path.join(output_dir, "text.md")
    formulas_path = os.path.join(output_dir, "formulas.tex")

    # æª¢æŸ¥æ˜¯å¦ç‚º URLï¼Œå¦‚æœæ˜¯å‰‡ä¸‹è¼‰åˆ°è¨˜æ†¶é«”
    if pdf_path.startswith(('http://', 'https://')):
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è¼‰ PDF å¾: {pdf_path}")
        try:
            response = requests.get(pdf_path, timeout=30)
            response.raise_for_status()
            print(f"âœ… PDF ä¸‹è¼‰æˆåŠŸï¼Œå¤§å°: {len(response.content)} bytes")
            
            # ç›´æ¥å¾è¨˜æ†¶é«”é–‹å•Ÿ PDF
            doc = fitz.open(stream=response.content, filetype="pdf")
            
        except Exception as e:
            print(f"âŒ PDF ä¸‹è¼‰å¤±æ•—: {e}")
            return False
    else:
        # æœ¬åœ°æª”æ¡ˆè·¯å¾‘
        if not os.path.exists(pdf_path):
            print(f"âŒ PDF æª”æ¡ˆä¸å­˜åœ¨: {pdf_path}")
            return False
        doc = fitz.open(pdf_path)

    # æ”¶é›†æ‰€æœ‰é é¢çš„æ–‡å­—å’Œä½ç½®è³‡è¨Š
    all_text_with_positions = []
    all_formulas = []
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        
        # ä½¿ç”¨å­—å…¸æ¨¡å¼ç²å–è©³ç´°çš„ä½ç½®å’Œæ ¼å¼è³‡è¨Š
        blocks = page.get_text("dict")
        
        for block in blocks["blocks"]:
            if "lines" in block:
                for line in block["lines"]:
                    line_text = ""
                    line_x_position = None
                    is_bold_line = False
                    
                    for span in line["spans"]:
                        text = span["text"]
                        flags = span["flags"]  # å­—é«”æ ¼å¼æ¨™èªŒ
                        bbox = span["bbox"]  # é‚Šç•Œæ¡† [x0, y0, x1, y1]
                        
                        # è¨˜éŒ„è¡Œçš„ x ä½ç½®ï¼ˆå·¦é‚Šè·ï¼‰
                        if line_x_position is None:
                            line_x_position = bbox[0]
                        
                        # æª¢æŸ¥æ˜¯å¦ç‚ºç²—é«”
                        if flags & 16:
                            is_bold_line = True
                            text = f"**{text.strip()}**"
                        
                        line_text += text
                    
                    if line_text.strip():
                        # å„²å­˜æ–‡å­—ã€ä½ç½®å’Œæ ¼å¼è³‡è¨Š
                        all_text_with_positions.append({
                            'text': line_text.strip(),
                            'x_position': line_x_position,
                            'is_bold': is_bold_line,
                            'page': page_num
                        })
                        
                        # æª¢æŸ¥æ˜¯å¦ç‚ºå…¬å¼è¡Œ
                        if re.search(r"[=âˆšâˆ‘âˆ«â‰¤â‰¥â‰ Ï€Ï„Î±Î²Î³]", line_text):
                            all_formulas.append(line_text.strip())
        
        # æ“·å–åœ–ç‰‡
        image_list = page.get_images(full=True)
        for img_idx, img in enumerate(image_list):
            xref = img[0]
            pix = fitz.Pixmap(doc, xref)
            if pix.n < 5:
                pix.save(os.path.join(img_dir, f"page{page_num+1}_img{img_idx+1}.png"))
            else:
                pix = fitz.Pixmap(fitz.csRGB, pix)
                pix.save(os.path.join(img_dir, f"page{page_num+1}_img{img_idx+1}.png"))
            pix = None  # æ¸…ç†è¨˜æ†¶é«”
    
    # æ‡‰ç”¨æ™ºèƒ½åˆ†æ®µè™•ç†ï¼ˆåŸºæ–¼ä½ç½®è®ŠåŒ–ï¼‰
    formatted_text = format_text_with_positions(all_text_with_positions)
    
    # å¯«å…¥è™•ç†å¾Œçš„æ–‡å­—
    with open(text_md_path, "w", encoding="utf-8") as text_file, \
         open(formulas_path, "w", encoding="utf-8") as formula_file:
        
        text_file.write("# PDF æ–‡å­—æå–çµæœ\n\n")
        text_file.write(formatted_text)
        
        # å¯«å…¥å…¬å¼
        for formula in all_formulas:
            formula_file.write(formula + "\n")

    doc.close()
    print(f"âœ… æå–å®Œæˆï¼š{pdf_path}")
    print(f"ğŸ“„ æ–‡å­—æª”ï¼š{text_md_path}")
    print(f"ğŸ“ å…¬å¼æª”ï¼š{formulas_path}")
    print(f"ğŸ–¼ï¸ åœ–ç‰‡è³‡æ–™å¤¾ï¼š{img_dir}")
    return True


def process_arxiv_paper(arxiv_id):
    """è™•ç†æŒ‡å®šçš„ arXiv è«–æ–‡"""
    
    # è¨­å®šè·¯å¾‘
    base_dir = f"/home/luluscavenger/AI_literature_agent-3/{arxiv_id}"
    pdf_path = os.path.join(base_dir, f"{arxiv_id}.pdf")
    
    print(f"ğŸ”¬ é–‹å§‹è™•ç† arXiv è«–æ–‡: {arxiv_id}")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {base_dir}")
    
    # æª¢æŸ¥ä¸¦ä¸‹è¼‰ PDF
    if not os.path.exists(pdf_path):
        print(f"ğŸ“ PDF ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¸‹è¼‰...")
        try:
            download_arxiv_pdf(arxiv_id, pdf_path)
        except Exception as e:
            print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
            return False
    else:
        print(f"ğŸ“ PDF å·²å­˜åœ¨: {pdf_path}")
    
    # æå–å…§å®¹
    try:
        print(f"ğŸ”„ é–‹å§‹æå–å…§å®¹...")
        extract_from_pdf(pdf_path, base_dir)
        
        # é¡¯ç¤ºçµæœçµ±è¨ˆ
        text_file = os.path.join(base_dir, "text.md")
        formula_file = os.path.join(base_dir, "formulas.tex")
        img_dir = os.path.join(base_dir, "images")
        
        print(f"\nğŸ“Š æå–çµæœçµ±è¨ˆ:")
        print(f"=" * 50)
        
        # æ–‡å­—æª”æ¡ˆçµ±è¨ˆ
        if os.path.exists(text_file):
            with open(text_file, 'r', encoding='utf-8') as f:
                text_content = f.read()
            print(f"ğŸ“„ æ–‡å­—æª”æ¡ˆ:")
            print(f"   - æª”æ¡ˆå¤§å°: {len(text_content):,} å­—ç¬¦")
            print(f"   - è¡Œæ•¸: {len(text_content.splitlines()):,} è¡Œ")
            print(f"   - æª”æ¡ˆè·¯å¾‘: {text_file}")
        
        # å…¬å¼æª”æ¡ˆçµ±è¨ˆ
        if os.path.exists(formula_file):
            with open(formula_file, 'r', encoding='utf-8') as f:
                formula_content = f.read()
            formula_lines = [line for line in formula_content.splitlines() if line.strip()]
            print(f"ğŸ“ å…¬å¼æª”æ¡ˆ:")
            print(f"   - å…¬å¼è¡Œæ•¸: {len(formula_lines)} è¡Œ")
            print(f"   - æª”æ¡ˆè·¯å¾‘: {formula_file}")
        
        # åœ–ç‰‡çµ±è¨ˆ
        if os.path.exists(img_dir):
            images = [f for f in os.listdir(img_dir) if f.endswith('.png')]
            print(f"ğŸ–¼ï¸ åœ–ç‰‡æª”æ¡ˆ:")
            print(f"   - åœ–ç‰‡æ•¸é‡: {len(images)} å¼µ")
            print(f"   - åœ–ç‰‡ç›®éŒ„: {img_dir}")
            
            if images:
                print(f"   - åœ–ç‰‡æ¸…å–®:")
                for img in sorted(images):
                    img_path = os.path.join(img_dir, img)
                    img_size = os.path.getsize(img_path)
                    print(f"     * {img} ({img_size:,} bytes)")
        
        print(f"=" * 50)
        print(f"âœ… æ‰€æœ‰æª”æ¡ˆå·²æˆåŠŸæå–ä¸¦å„²å­˜åˆ°: {base_dir}")
        return True
        
    except Exception as e:
        print(f"âŒ æå–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_arxiv_2507_15389():
    """æ¸¬è©¦ arXiv 2507.15389 è«–æ–‡æå–"""
    return process_arxiv_paper("2507.15389")


if __name__ == "__main__":
    import sys
    
    # æª¢æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œåƒæ•¸
    if len(sys.argv) > 1:
        arxiv_id = sys.argv[1]
        print(f"ğŸ¯ æ¥æ”¶åˆ° arXiv ID: {arxiv_id}")
        success = process_arxiv_paper(arxiv_id)
        if success:
            print(f"ğŸ‰ è™•ç†å®Œæˆï¼")
        else:
            print(f"ğŸ’¥ è™•ç†å¤±æ•—ï¼")
            sys.exit(1)
    else:
        # æ²’æœ‰åƒæ•¸æ™‚ï¼Œé‹è¡Œé è¨­æ¸¬è©¦
        print("ğŸ“‹ æ²’æœ‰æä¾› arXiv IDï¼Œé‹è¡Œé è¨­æ¸¬è©¦...")
        test_arxiv_2507_15389()
