import os
import re
import json
from typing import Dict, List, Any
from pathlib import Path

def split_MD(md_file_path: str, output_dir: str = None) -> Dict[str, List[str]]:
    """
    åˆ†æ MD æ–‡ä»¶ä¸¦å‰µå»ºçµæ§‹åŒ–å­—å…¸ï¼Œä¿å­˜ç‚ºç¨ç«‹çš„ MD æ–‡ä»¶
    
    Args:
        md_file_path: MD æ–‡ä»¶è·¯å¾‘
        output_dir: è¼¸å‡ºç›®éŒ„ï¼ˆå¯é¸ï¼Œé»˜èªæœƒåœ¨md_file_pathçš„åŒç›®éŒ„ä¸‹å‰µå»ºtextåˆ†æ®µæ–‡ä»¶ï¼‰
    
    Returns:
        å­—å…¸æ ¼å¼: {"sectionA/subsectionB/subsubsectionC": [paragraph_1, paragraph_2, formula_1, ...]}
    """
    
    if not os.path.exists(md_file_path):
        print(f"âŒ MD æ–‡ä»¶ä¸å­˜åœ¨: {md_file_path}")
        return {}
    
    # è®€å– MD æ–‡ä»¶
    with open(md_file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # åˆ†å‰²æˆè¡Œ
    lines = content.split('\n')
    
    # çµæœå­—å…¸
    result = {}
    
    # ç•¶å‰ç« ç¯€è·¯å¾‘
    current_path = []
    current_content = []
    
    # è™•ç†æ¯ä¸€è¡Œ
    for line in lines:
        line = line.strip()
        
        # è·³éç©ºè¡Œ
        if not line:
            continue
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¨™é¡Œ
        if line.startswith('#'):
            # ä¿å­˜ä¹‹å‰çš„å…§å®¹
            if current_path and current_content:
                section_key = '/'.join(current_path)
                if section_key in result:
                    result[section_key].extend(current_content)
                else:
                    result[section_key] = current_content[:]
                current_content = []
            
            # è§£ææ–°æ¨™é¡Œ
            level = 0
            while level < len(line) and line[level] == '#':
                level += 1
            
            title = line[level:].strip()
            
            # æ¸…ç†æ¨™é¡Œï¼ˆç§»é™¤ç·¨è™Ÿï¼‰
            title = re.sub(r'^\d+\.?\s*', '', title)
            title = re.sub(r'^\w+\.\s*', '', title)  # ç§»é™¤å¦‚ "1.1 " æ ¼å¼
            
            # æ›´æ–°è·¯å¾‘
            if level == 1:
                current_path = [title]
            elif level == 2:
                if len(current_path) >= 1:
                    current_path = current_path[:1] + [title]
                else:
                    current_path = [title]
            elif level == 3:
                if len(current_path) >= 2:
                    current_path = current_path[:2] + [title]
                else:
                    current_path.extend([title])
            elif level == 4:
                if len(current_path) >= 3:
                    current_path = current_path[:3] + [title]
                else:
                    current_path.extend([title])
            elif level >= 5:
                if len(current_path) >= 4:
                    current_path = current_path[:4] + [title]
                else:
                    current_path.extend([title])
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ•¸å­¸å…¬å¼
        elif line.startswith('$$') and line.endswith('$$'):
            current_content.append(line)
        elif line.startswith('$') and line.endswith('$') and len(line) > 2:
            current_content.append(line)
        
        # æ™®é€šå…§å®¹
        else:
            # è·³éä¸€äº›ä¸éœ€è¦çš„è¡Œ
            skip_patterns = [
                r'^#+\s*$',  # åªæœ‰ # çš„è¡Œ
                r'^\*+\s*$',  # åªæœ‰ * çš„è¡Œ
                r'^-+\s*$',   # åªæœ‰ - çš„è¡Œ
                r'^=+\s*$',   # åªæœ‰ = çš„è¡Œ
                r'^\s*\|\s*$',  # è¡¨æ ¼åˆ†éš”ç¬¦
                r'^\s*```\s*$',  # ä»£ç¢¼å¡Šæ¨™è¨˜
            ]
            
            should_skip = any(re.match(pattern, line) for pattern in skip_patterns)
            
            if not should_skip and len(line) > 5:  # åªä¿ç•™æœ‰æ„ç¾©çš„å…§å®¹
                current_content.append(line)
    
    # ä¿å­˜æœ€å¾Œçš„å…§å®¹
    if current_path and current_content:
        section_key = '/'.join(current_path)
        if section_key in result:
            result[section_key].extend(current_content)
        else:
            result[section_key] = current_content
    
    # æ¸…ç†çµæœ
    cleaned_result = {}
    for key, content_list in result.items():
        if content_list:  # åªä¿ç•™éç©ºå…§å®¹
            # åˆä½µç›¸é„°çš„çŸ­æ®µè½
            merged_content = merge_short_paragraphs(content_list)
            cleaned_result[key] = merged_content
    
    # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆç¸½æ˜¯ä¿å­˜ï¼Œé è¨­åœ¨mdæª”æ¡ˆçš„åŒç›®éŒ„ï¼‰
    if not output_dir:
        # é»˜èªåœ¨md_file_pathçš„åŒç›®éŒ„ä¸‹å‰µå»ºtextåˆ†æ®µæ–‡ä»¶
        md_dir = os.path.dirname(md_file_path)
        output_dir = md_dir
        
    os.makedirs(output_dir, exist_ok=True)
    
    # ç”Ÿæˆç« ç¯€ç·¨è™Ÿæ˜ å°„
    section_numbers = generate_section_numbers(cleaned_result)
    
    # ä¿å­˜æ¯å€‹ç« ç¯€ç‚ºç¨ç«‹çš„ MD æ–‡ä»¶
    file_count = 0
    segment_previews = []  # å„²å­˜æ¯æ®µçš„é è¦½ä¿¡æ¯
    
    for section_path, content_list in cleaned_result.items():
        section_number = section_numbers.get(section_path, str(file_count + 1))
        
        # å°‡å…§å®¹åˆ†æ®µä¿å­˜
        for paragraph_idx, paragraph in enumerate(content_list, 1):
            file_count += 1
            filename = f"text{section_number}-{paragraph_idx}.md"
            file_path = os.path.join(output_dir, filename)
            
            # å‰µå»º MD æ–‡ä»¶å…§å®¹
            md_content = create_md_file_content(section_path, paragraph, section_number, paragraph_idx)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(md_content)
            
            # å–å¾—æ®µè½é–‹é ­20å€‹å­—ä½œç‚ºé è¦½
            preview_text = paragraph[:20] if len(paragraph) > 20 else paragraph
            preview_text = preview_text.replace('\n', ' ').strip()
            segment_previews.append({
                'filename': filename,
                'section': section_path,
                'preview': preview_text,
                'full_length': len(paragraph)
            })
    
    # å‰µå»ºç´¢å¼•æ–‡ä»¶
    create_index_file(output_dir, cleaned_result, section_numbers)
    
    # åœ¨çµ‚ç«¯æ©Ÿå°å‡ºåˆ†æ®µé è¦½
    print(f"\nğŸ“„ åˆ†æ®µé è¦½ - æ¯æ®µé–‹é ­å…§å®¹:")
    print("="*80)
    for preview in segment_previews:
        print(f"ğŸ“ {preview['filename']}")
        print(f"   ç« ç¯€: {preview['section']}")
        print(f"   é–‹é ­: {preview['preview']}...")
        print(f"   é•·åº¦: {preview['full_length']} å­—ç¬¦")
        print("-"*50)
    
    print(f"\nâœ… åˆ†æ®µ MD æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_dir}")
    print(f"ğŸ“Š å…±ç”Ÿæˆ {file_count} å€‹ MD æ–‡ä»¶")
    print(f"ğŸ“‹ ç´¢å¼•æ–‡ä»¶: {os.path.join(output_dir, 'index.md')}")
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼Œå…±æå– {len(cleaned_result)} å€‹ç« ç¯€")
    for section in cleaned_result.keys():
        print(f"   ğŸ“š {section} ({len(cleaned_result[section])} é …å…§å®¹)")
    
    return cleaned_result

def merge_short_paragraphs(content_list: List[str], min_length: int = 50) -> List[str]:
    """åˆä½µéçŸ­çš„æ®µè½ä»¥æé«˜å¯è®€æ€§"""
    if not content_list:
        return []
    
    merged = []
    current_paragraph = ""
    
    for item in content_list:
        # å¦‚æœæ˜¯å…¬å¼ï¼Œç›´æ¥æ·»åŠ 
        if (item.startswith('$$') and item.endswith('$$')) or (item.startswith('$') and item.endswith('$')):
            if current_paragraph:
                merged.append(current_paragraph.strip())
                current_paragraph = ""
            merged.append(item)
        
        # å¦‚æœæ˜¯æ™®é€šæ–‡å­—
        else:
            if len(item) < min_length and current_paragraph:
                # åˆä½µçŸ­æ®µè½
                current_paragraph += " " + item
            else:
                # ä¿å­˜ä¹‹å‰çš„æ®µè½
                if current_paragraph:
                    merged.append(current_paragraph.strip())
                current_paragraph = item
    
    # æ·»åŠ æœ€å¾Œçš„æ®µè½
    if current_paragraph:
        merged.append(current_paragraph.strip())
    
    return merged

def generate_section_numbers(cleaned_result: Dict[str, List[str]]) -> Dict[str, str]:
    """ç”Ÿæˆç« ç¯€ç·¨è™Ÿæ˜ å°„"""
    section_numbers = {}
    main_sections = {}  # ä¸»ç« ç¯€è¨ˆæ•¸
    
    for section_path in cleaned_result.keys():
        parts = section_path.split('/')
        
        if len(parts) == 1:
            # ä¸»ç« ç¯€ (å¦‚ "Introduction")
            if parts[0] not in main_sections:
                main_sections[parts[0]] = len(main_sections) + 1
            section_numbers[section_path] = str(main_sections[parts[0]])
        
        elif len(parts) == 2:
            # å­ç« ç¯€ (å¦‚ "Introduction/Background")
            main_section = parts[0]
            if main_section not in main_sections:
                main_sections[main_section] = len(main_sections) + 1
            
            # è¨ˆç®—å­ç« ç¯€ç·¨è™Ÿ
            sub_count = sum(1 for key in section_numbers.keys() 
                          if key.startswith(main_section + '/') and len(key.split('/')) == 2)
            section_numbers[section_path] = f"{main_sections[main_section]}-{sub_count + 1}"
        
        elif len(parts) >= 3:
            # å­å­ç« ç¯€åŠæ›´æ·±å±¤æ¬¡
            main_section = parts[0]
            parent_path = '/'.join(parts[:2])
            
            if main_section not in main_sections:
                main_sections[main_section] = len(main_sections) + 1
            
            # ç¢ºä¿çˆ¶ç« ç¯€æœ‰ç·¨è™Ÿ
            if parent_path not in section_numbers:
                parent_count = sum(1 for key in section_numbers.keys() 
                                 if key.startswith(main_section + '/') and len(key.split('/')) == 2)
                section_numbers[parent_path] = f"{main_sections[main_section]}-{parent_count + 1}"
            
            # è¨ˆç®—ç•¶å‰ç« ç¯€ç·¨è™Ÿ
            sub_count = sum(1 for key in section_numbers.keys() 
                          if key.startswith(parent_path + '/'))
            parent_num = section_numbers[parent_path]
            section_numbers[section_path] = f"{parent_num}-{sub_count + 1}"
    
    return section_numbers

def create_md_file_content(section_path: str, paragraph: str, section_number: str, paragraph_idx: int) -> str:
    """å‰µå»º MD æ–‡ä»¶å…§å®¹"""
    
    # å¾è·¯å¾‘ä¸­æå–ç« ç¯€æ¨™é¡Œ
    section_parts = section_path.split('/')
    section_title = section_parts[-1]  # ä½¿ç”¨æœ€å¾Œä¸€ç´šä½œç‚ºæ¨™é¡Œ
    
    # æ§‹å»º MD å…§å®¹
    md_content = f"""# {section_title}

**ç« ç¯€è·¯å¾‘**: {section_path}  
**ç« ç¯€ç·¨è™Ÿ**: {section_number}  
**æ®µè½ç·¨è™Ÿ**: {paragraph_idx}

---

{paragraph}

---

*æ–‡ä»¶ç”Ÿæˆæ™‚é–“: {get_current_time()}*
*ä¾†æºç« ç¯€: {section_path}*
"""
    
    return md_content

def create_index_file(output_dir: str, cleaned_result: Dict[str, List[str]], section_numbers: Dict[str, str]):
    """å‰µå»ºç´¢å¼•æ–‡ä»¶"""
    
    index_path = os.path.join(output_dir, 'index.md')
    
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write("# æ–‡æª”åˆ†æ®µç´¢å¼•\n\n")
        f.write(f"**ç”Ÿæˆæ™‚é–“**: {get_current_time()}\n")
        f.write(f"**ç¸½ç« ç¯€æ•¸**: {len(cleaned_result)}\n\n")
        
        f.write("## æ–‡ä»¶åˆ—è¡¨\n\n")
        
        file_count = 0
        for section_path, content_list in cleaned_result.items():
            section_number = section_numbers.get(section_path, 'unknown')
            
            f.write(f"### {section_path}\n")
            f.write(f"**ç« ç¯€ç·¨è™Ÿ**: {section_number}\n")
            f.write(f"**æ®µè½æ•¸é‡**: {len(content_list)}\n\n")
            
            for paragraph_idx in range(1, len(content_list) + 1):
                file_count += 1
                filename = f"text{section_number}-{paragraph_idx}.md"
                f.write(f"- [{filename}](./{filename}) - ç¬¬{paragraph_idx}æ®µ\n")
            
            f.write("\n")
        
        f.write(f"\n**ç¸½æ–‡ä»¶æ•¸**: {file_count}\n")

def get_current_time() -> str:
    """ç²å–ç•¶å‰æ™‚é–“å­—ç¬¦ä¸²"""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def process_extracted_documents(base_dir: str = "./extracted_docs"):
    """
    è™•ç†æ‰€æœ‰å·²æå–çš„æ–‡æª”
    
    Args:
        base_dir: åŒ…å«æå–æ–‡æª”çš„åŸºç¤ç›®éŒ„
    """
    
    # å®šç¾©å·²çŸ¥çš„æ–‡æª”
    documents = {
        "html_2507.21856": os.path.join(base_dir, "2507.21856"),
        "latex_2110.01975": os.path.join(base_dir, "2110.01975"), 
        "pdf_2507.15389": os.path.join(base_dir, "2507.15389")
    }
    
    results = {}
    
    for doc_name, doc_path in documents.items():
        print(f"\nğŸ” è™•ç†æ–‡æª”: {doc_name}")
        print(f"ğŸ“ è·¯å¾‘: {doc_path}")
        
        if not os.path.exists(doc_path):
            print(f"âš ï¸ ç›®éŒ„ä¸å­˜åœ¨: {doc_path}")
            continue
        
        # æŸ¥æ‰¾ MD æ–‡ä»¶
        md_file = os.path.join(doc_path, "text.md")
        if not os.path.exists(md_file):
            print(f"âš ï¸ MD æ–‡ä»¶ä¸å­˜åœ¨: {md_file}")
            continue
        
        # ç›´æ¥åœ¨åŸå§‹ç›®éŒ„ä¸­å‰µå»ºåˆ†æ®µæ–‡ä»¶ï¼Œä¸ä½¿ç”¨å­ç›®éŒ„
        # åˆ†æ MD æ–‡ä»¶
        try:
            structured_content = split_MD(md_file)  # ä¸æŒ‡å®šoutput_dirï¼Œä½¿ç”¨é»˜èªè¡Œç‚º
            results[doc_name] = structured_content
            
            # æª¢æŸ¥åœ–ç‰‡æ–‡ä»¶å¤¾
            img_dir = os.path.join(doc_path, "images")
            if os.path.exists(img_dir):
                img_files = [f for f in os.listdir(img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.pdf'))]
                print(f"ğŸ–¼ï¸ ä¿æŒ {len(img_files)} å€‹åœ–ç‰‡æ–‡ä»¶ä¸è®Š")
            else:
                print("ğŸ“· æœªæ‰¾åˆ°åœ–ç‰‡æ–‡ä»¶å¤¾")
                
        except Exception as e:
            print(f"âŒ è™•ç† {doc_name} æ™‚å‡ºéŒ¯: {e}")
            continue
    
    # ç”Ÿæˆç¸½çµå ±å‘Š
    summary_file = os.path.join(base_dir, "processing_summary.txt")
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write("æ–‡æª”è™•ç†ç¸½çµå ±å‘Š\n")
        f.write("="*50 + "\n\n")
        
        for doc_name, content in results.items():
            f.write(f"æ–‡æª”: {doc_name}\n")
            f.write(f"ç« ç¯€æ•¸é‡: {len(content)}\n")
            f.write("ç« ç¯€åˆ—è¡¨:\n")
            for section in content.keys():
                f.write(f"  - {section}\n")
            f.write("\n" + "-"*30 + "\n\n")
    
    print(f"\nğŸ“Š è™•ç†å®Œæˆ! ç¸½çµå ±å‘Š: {summary_file}")
    return results

def analyze_document_structure(md_file_path: str):
    """åˆ†ææ–‡æª”çµæ§‹ä¸¦é¡¯ç¤ºç« ç¯€å±¤æ¬¡"""
    
    if not os.path.exists(md_file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {md_file_path}")
        return
    
    with open(md_file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    lines = content.split('\n')
    
    print(f"ğŸ“– åˆ†ææ–‡æª”çµæ§‹: {os.path.basename(md_file_path)}")
    print("="*60)
    
    for i, line in enumerate(lines, 1):
        line = line.strip()
        if line.startswith('#'):
            level = 0
            while level < len(line) and line[level] == '#':
                level += 1
            
            title = line[level:].strip()
            indent = "  " * (level - 1)
            print(f"{indent}{'#' * level} {title} (è¡Œ {i})")

def test_with_current_file():
    """æ¸¬è©¦å‡½æ•¸ï¼Œè‡ªå‹•å°‹æ‰¾ä¸¦è™•ç†å¯ç”¨çš„ text.md æ–‡ä»¶"""
    
    # å°‹æ‰¾å¯ç”¨çš„ text.md æ–‡ä»¶
    possible_files = [
        "../../2103.01086/text.md",
        "../../2110.08629/text.md", 
        "../../2507.15389/text.md",
        "../../2210.11378/text.md",
        "./test_h2_p_extract/text.md"
    ]
    
    test_file = None
    for file_path in possible_files:
        if os.path.exists(file_path):
            test_file = file_path
            break
    
    if not test_file:
        print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æ¸¬è©¦æ–‡ä»¶")
        print("ğŸ” æ­£åœ¨æœå°‹å·¥ä½œå€ä¸­çš„ MD æ–‡ä»¶...")
        
        # æœå°‹æ•´å€‹å·¥ä½œå€çš„ MD æ–‡ä»¶
        import glob
        md_files = []
        
        # æœå°‹ç•¶å‰ç›®éŒ„å’Œä¸Šç´šç›®éŒ„
        for pattern in ["*.md", "../*.md", "../../*/*.md", "../../../*/*.md"]:
            md_files.extend(glob.glob(pattern))
        
        # éæ¿¾æ‰ä¸€äº›ä¸éœ€è¦çš„æ–‡ä»¶
        filtered_files = []
        skip_patterns = ['index', 'README', 'prompt', 'sample']
        
        for file in md_files:
            filename = os.path.basename(file).lower()
            if not any(pattern in filename for pattern in skip_patterns):
                if os.path.getsize(file) > 1000:  # è‡³å°‘1KB
                    filtered_files.append(file)
        
        if not filtered_files:
            print("âŒ æœªæ‰¾åˆ°åˆé©çš„ MD æ–‡ä»¶")
            return
        
        print(f"ğŸ“„ æ‰¾åˆ° {len(filtered_files)} å€‹å¯ç”¨çš„ MD æ–‡ä»¶:")
        for i, file in enumerate(filtered_files[:5]):  # åªé¡¯ç¤ºå‰5å€‹
            size_kb = os.path.getsize(file) // 1024
            print(f"   {i+1}. {file} ({size_kb}KB)")
        
        # ä½¿ç”¨ç¬¬ä¸€å€‹æ‰¾åˆ°çš„æ–‡ä»¶
        test_file = filtered_files[0]
        print(f"\nâœ… é¸æ“‡æ–‡ä»¶: {test_file}")
    
    print("ğŸ§ª æ¸¬è©¦ split_MD å‡½æ•¸ - ä½¿ç”¨å¯¦éš›æ–‡ä»¶")
    print(f"ğŸ“„ æ¸¬è©¦æ–‡ä»¶: {test_file}")
    
    # è¨­ç½®è¼¸å‡ºç›®éŒ„ç‚ºæ–‡ä»¶æ‰€åœ¨ç›®éŒ„çš„åˆ†æ®µå­æ–‡ä»¶å¤¾
    output_dir = os.path.join(os.path.dirname(test_file), "åˆ†æ®µæ–‡ä»¶")
    result = split_MD(test_file, output_dir)
    
    print(f"\nğŸ“‹ è™•ç†çµæœæ¦‚è¦:")
    print(f"   ç¸½ç« ç¯€æ•¸: {len(result)}")
    for section, content in result.items():
        print(f"   ğŸ“š {section}: {len(content)} æ®µ")

# æ¸¬è©¦å‡½æ•¸
def test_split_md():
    """æ¸¬è©¦ split_MD å‡½æ•¸"""
    
    # å‰µå»ºæ¸¬è©¦ MD å…§å®¹
    test_content = """# Introduction
This is the introduction section.

Some more introduction text.

## Background
Background information here.

### Technical Details
Technical details subsection.

More technical content.

$$E = mc^2$$

Another paragraph after formula.

## Methods
Methods section content.

### Data Collection
Data collection details.

### Analysis
Analysis methodology.

# Results
Results section.

## Findings
Our findings are presented here.

# Conclusion
Final conclusions.
"""
    
    # å‰µå»ºæ¸¬è©¦æ–‡ä»¶
    test_file = "/tmp/test_document.md"
    with open(test_file, 'w', encoding='utf-8') as f:
        f.write(test_content)
    
    print("ğŸ§ª æ¸¬è©¦ split_MD å‡½æ•¸")
    result = split_MD(test_file, "/tmp/test_output")
    
    print("\nğŸ“‹ æ¸¬è©¦çµæœ:")
    for section, content in result.items():
        print(f"\nç« ç¯€: {section}")
        for i, item in enumerate(content[:3], 1):  # åªé¡¯ç¤ºå‰3é …
            print(f"  {i}. {item[:100]}...")

def split_MD_with_simple_naming(md_file_path: str, output_dir: str) -> Dict[str, List[str]]:
    """
    åˆ†æ MD æ–‡ä»¶ä¸¦å‰µå»ºç°¡å–®å‘½åçš„åˆ†æ®µæ–‡ä»¶ (å¦‚ 2-3.md = ç¬¬äºŒç« ç¬¬ä¸‰æ®µ)
    
    Args:
        md_file_path: MD æ–‡ä»¶è·¯å¾‘
        output_dir: è¼¸å‡ºç›®éŒ„
    
    Returns:
        å­—å…¸æ ¼å¼: {"section_name": [paragraph_1, paragraph_2, ...]}
    """
    
    if not os.path.exists(md_file_path):
        print(f"âŒ MD æ–‡ä»¶ä¸å­˜åœ¨: {md_file_path}")
        return {}
    
    # è®€å– MD æ–‡ä»¶
    with open(md_file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # åˆ†å‰²æˆè¡Œ
    lines = content.split('\n')
    
    # çµæœå­—å…¸
    result = {}
    
    # ç•¶å‰ç« ç¯€ä¿¡æ¯
    current_chapter = 0
    current_section = 0
    current_content = []
    current_section_name = ""
    
    # è™•ç†æ¯ä¸€è¡Œ
    for line in lines:
        line = line.strip()
        
        # è·³éç©ºè¡Œ
        if not line:
            continue
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¨™é¡Œ
        if line.startswith('#'):
            # ä¿å­˜ä¹‹å‰çš„å…§å®¹
            if current_section_name and current_content:
                if current_section_name in result:
                    result[current_section_name].extend(current_content)
                else:
                    result[current_section_name] = current_content[:]
                current_content = []
            
            # è§£ææ–°æ¨™é¡Œ
            level = 0
            while level < len(line) and line[level] == '#':
                level += 1
            
            title = line[level:].strip()
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºç« ç¯€æ¨™é¡Œï¼ˆåŒ…å«æ•¸å­—ï¼‰
            chapter_match = re.search(r'^(\d+)', title)
            if chapter_match and level <= 2:  # ä¸»ç« ç¯€
                current_chapter = int(chapter_match.group(1))
                current_section = 0
                current_section_name = f"{current_chapter}"
            elif level > 2:  # å­ç« ç¯€
                current_section += 1
                current_section_name = f"{current_chapter}-{current_section}"
            else:
                # å¦‚æœæ²’æœ‰æ•¸å­—ï¼Œä½¿ç”¨åºè™Ÿ
                if level == 1:
                    current_chapter += 1
                    current_section = 0
                    current_section_name = f"{current_chapter}"
                else:
                    current_section += 1
                    current_section_name = f"{current_chapter}-{current_section}"
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºç¨‹å¼ç¢¼å€å¡Š
        elif line.startswith('```'):
            current_content.append(line)
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ•¸å­¸å…¬å¼
        elif line.startswith('$$') and line.endswith('$$'):
            current_content.append(line)
        elif line.startswith('$') and line.endswith('$') and len(line) > 2:
            current_content.append(line)
        
        # æ™®é€šå…§å®¹
        else:
            # è·³éä¸€äº›ä¸éœ€è¦çš„è¡Œ
            skip_patterns = [
                r'^#+\s*$',  # åªæœ‰ # çš„è¡Œ
                r'^\*+\s*$',  # åªæœ‰ * çš„è¡Œ
                r'^-+\s*$',   # åªæœ‰ - çš„è¡Œ
                r'^=+\s*$',   # åªæœ‰ = çš„è¡Œ
                r'^\s*\|\s*$',  # è¡¨æ ¼åˆ†éš”ç¬¦
            ]
            
            should_skip = any(re.match(pattern, line) for pattern in skip_patterns)
            
            if not should_skip and len(line) > 5:  # åªä¿ç•™æœ‰æ„ç¾©çš„å…§å®¹
                current_content.append(line)
    
    # ä¿å­˜æœ€å¾Œçš„å…§å®¹
    if current_section_name and current_content:
        if current_section_name in result:
            result[current_section_name].extend(current_content)
        else:
            result[current_section_name] = current_content
    
    # æ¸…ç†å’Œåˆä½µçŸ­æ®µè½
    cleaned_result = {}
    for key, content_list in result.items():
        if content_list:  # åªä¿ç•™éç©ºå…§å®¹
            merged_content = merge_short_paragraphs(content_list)
            cleaned_result[key] = merged_content
    
    # ä¿å­˜åˆ†æ®µæ–‡ä»¶
    os.makedirs(output_dir, exist_ok=True)
    
    file_count = 0
    segment_previews = []  # å„²å­˜æ¯æ®µçš„é è¦½ä¿¡æ¯
    
    for section_key, content_list in cleaned_result.items():
        # å°‡å…§å®¹åˆ†æ®µä¿å­˜
        for paragraph_idx, paragraph in enumerate(content_list, 1):
            file_count += 1
            
            # æª¢æŸ¥æ®µè½æ˜¯å¦åŒ…å«ç¨‹å¼ç¢¼
            has_code = '```' in paragraph or paragraph.count('`') >= 2
            
            # æ ¹æ“šå…§å®¹é¡å‹èª¿æ•´æª”å
            if has_code:
                filename = f"{section_key}-{paragraph_idx}_code.md"
            else:
                filename = f"{section_key}-{paragraph_idx}.md"
                
            file_path = os.path.join(output_dir, filename)
            
            # å‰µå»ºç°¡å–®çš„ MD æ–‡ä»¶å…§å®¹
            md_content = create_simple_md_content(section_key, paragraph, paragraph_idx, has_code)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(md_content)
            
            # å–å¾—æ®µè½é–‹é ­20å€‹å­—ä½œç‚ºé è¦½
            preview_text = paragraph[:20] if len(paragraph) > 20 else paragraph
            preview_text = preview_text.replace('\n', ' ').strip()
            segment_previews.append({
                'filename': filename,
                'section': section_key,
                'preview': preview_text,
                'full_length': len(paragraph),
                'content_type': 'code' if has_code else 'text'
            })
    
    # å‰µå»ºç°¡å–®ç´¢å¼•æ–‡ä»¶
    create_simple_index_file(output_dir, cleaned_result)
    
    # åœ¨çµ‚ç«¯æ©Ÿå°å‡ºåˆ†æ®µé è¦½
    print(f"\nğŸ“„ åˆ†æ®µé è¦½ - æ¯æ®µé–‹é ­å…§å®¹:")
    print("="*80)
    for preview in segment_previews:
        content_type_icon = "ğŸ’»" if preview.get('content_type') == 'code' else "ğŸ“"
        print(f"{content_type_icon} {preview['filename']}")
        print(f"   ç« ç¯€: {preview['section']}")
        print(f"   é¡å‹: {preview.get('content_type', 'text')}")
        print(f"   é–‹é ­: {preview['preview']}...")
        print(f"   é•·åº¦: {preview['full_length']} å­—ç¬¦")
        print("-"*50)
    
    # çµ±è¨ˆä¸åŒé¡å‹çš„æ–‡ä»¶æ•¸é‡
    code_files = len([p for p in segment_previews if p.get('content_type') == 'code'])
    text_files = len([p for p in segment_previews if p.get('content_type') == 'text'])
    
    print(f"\nâœ… åˆ†æ®µ MD æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_dir}")
    print(f"ğŸ“Š å…±ç”Ÿæˆ {file_count} å€‹ MD æ–‡ä»¶")
    print(f"ğŸ’» ç¨‹å¼ç¢¼æ–‡ä»¶: {code_files} å€‹")
    print(f"ğŸ“ æ–‡å­—æ–‡ä»¶: {text_files} å€‹")
    print(f"ğŸ“‹ ç´¢å¼•æ–‡ä»¶: {os.path.join(output_dir, 'index.md')}")
    
    return cleaned_result

def create_simple_md_content(section_key: str, paragraph: str, paragraph_idx: int, has_code: bool = False) -> str:
    """å‰µå»ºç°¡å–®çš„ MD æ–‡ä»¶å…§å®¹"""
    
    content_type = "ç¨‹å¼ç¢¼å€å¡Š" if has_code else "æ–‡å­—å…§å®¹"
    
    md_content = f"""# ç« ç¯€ {section_key} - æ®µè½ {paragraph_idx}{' (ç¨‹å¼ç¢¼)' if has_code else ''}

**ç« ç¯€ç·¨è™Ÿ**: {section_key}  
**æ®µè½ç·¨è™Ÿ**: {paragraph_idx}  
**å…§å®¹é¡å‹**: {content_type}

---

{paragraph}

---

*æ–‡ä»¶ç”Ÿæˆæ™‚é–“: {get_current_time()}*
*ç« ç¯€: {section_key}*
*é¡å‹: {content_type}*
"""
    
    return md_content

def create_simple_index_file(output_dir: str, cleaned_result: Dict[str, List[str]]):
    """å‰µå»ºç°¡å–®ç´¢å¼•æ–‡ä»¶"""
    
    index_path = os.path.join(output_dir, 'index.md')
    
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write("# æ–‡æª”åˆ†æ®µç´¢å¼•\n\n")
        f.write(f"**ç”Ÿæˆæ™‚é–“**: {get_current_time()}\n")
        f.write(f"**ç¸½ç« ç¯€æ•¸**: {len(cleaned_result)}\n\n")
        
        f.write("## æ–‡ä»¶åˆ—è¡¨\n\n")
        
        file_count = 0
        for section_key, content_list in cleaned_result.items():
            f.write(f"### ç« ç¯€ {section_key}\n")
            f.write(f"**æ®µè½æ•¸é‡**: {len(content_list)}\n\n")
            
            for paragraph_idx in range(1, len(content_list) + 1):
                file_count += 1
                filename = f"{section_key}-{paragraph_idx}.md"
                f.write(f"- [{filename}](./{filename}) - ç¬¬{paragraph_idx}æ®µ\n")
            
            f.write("\n")
        
        f.write(f"\n**ç¸½æ–‡ä»¶æ•¸**: {file_count}\n")

if __name__ == "__main__":
    print("ğŸš€ MD æ–‡ä»¶åˆ†æ®µå·¥å…·")
    print("=" * 50)
    
    # æª¢æŸ¥å‘½ä»¤è¡Œåƒæ•¸
    import sys
    if len(sys.argv) > 1:
        # å¦‚æœæä¾›äº†æ–‡ä»¶è·¯å¾‘åƒæ•¸
        input_file = sys.argv[1]
        if os.path.exists(input_file) and input_file.endswith('.md'):
            print(f"ğŸ“„ è™•ç†æŒ‡å®šæ–‡ä»¶: {input_file}")
            output_dir = os.path.join(os.path.dirname(input_file), "åˆ†æ®µæ–‡ä»¶")
            result = split_MD(input_file, output_dir)
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯ MD æ–‡ä»¶: {input_file}")
    else:
        # ä½¿ç”¨æ¸¬è©¦å‡½æ•¸è‡ªå‹•å°‹æ‰¾æ–‡ä»¶
        test_with_current_file()
    
    print("\nâœ… è™•ç†å®Œæˆï¼")
